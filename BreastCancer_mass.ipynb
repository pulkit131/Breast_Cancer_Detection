{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import seaborn as sns\n",
        "\n",
        "import cv2\n",
        "from matplotlib.image import imread\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import glob\n",
        "import PIL\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "nDeIOCT0zNmF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "!pip install albumentations opencv-python matplotlib"
      ],
      "metadata": {
        "id": "aPlVEx0e--Fw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt0\n",
        "from tqdm import tqdm\n",
        "import random"
      ],
      "metadata": {
        "id": "qVj2cEQM--CD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = '/content/dataset_folder'\n"
      ],
      "metadata": {
        "id": "ZxaO95Qw9zUd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "kaggle_dir = os.path.expanduser(\"~/.kaggle\")\n",
        "os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "# Move kaggle.json to the correct location\n",
        "with open(\"/content/kaggle.json\", \"r\") as f:\n",
        "    kaggle_credentials = json.load(f)\n",
        "\n",
        "with open(os.path.join(kaggle_dir, \"kaggle.json\"), \"w\") as f:\n",
        "    json.dump(kaggle_credentials, f)\n",
        "\n",
        "os.chmod(os.path.join(kaggle_dir, \"kaggle.json\"), 0o600)  # Secure fileÂ permissions"
      ],
      "metadata": {
        "id": "pJrcCq_Z5x3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Define dataset folder\n",
        "dataset_folder = \"/content/dataset_folder\"\n",
        "os.makedirs(dataset_folder, exist_ok=True)  # Ensure the folder exists\n",
        "\n",
        "# Download and extract dataset\n",
        "!kaggle datasets download -d awsaf49/cbis-ddsm-breast-cancer-image-dataset -p \"{dataset_folder}\"\n",
        "!unzip -q \"{dataset_folder}/cbis-ddsm-breast-cancer-image-dataset.zip\" -d \"{dataset_folder}\"\n"
      ],
      "metadata": {
        "id": "dhJt51jg--AA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_folder = '/content/dataset_folder'\n"
      ],
      "metadata": {
        "id": "xU2L36iY8zwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_data = pd.read_csv(os.path.join(dataset_folder, 'csv', 'dicom_info.csv'))\n",
        "\n",
        "mass_case_train_df = pd.read_csv(os.path.join(dataset_folder, 'csv', 'mass_case_description_train_set.csv'))\n",
        "mass_case_test_df = pd.read_csv(os.path.join(dataset_folder, 'csv', 'mass_case_description_test_set.csv'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vn_e4ALA8bzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mass_case_df = pd.concat([mass_case_train_df, mass_case_test_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "FrNTlNyEQLi7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "onKvxcUG4JcY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = os.path.join(dataset_folder, 'jpeg')  # Extract images here\n"
      ],
      "metadata": {
        "id": "N6_chX1M26qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_data.head()"
      ],
      "metadata": {
        "id": "_4_5GPcR1Z_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dicom_data.info()"
      ],
      "metadata": {
        "id": "am3zMHGD1kvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_series_descriptions = dicom_data['SeriesDescription'].unique()\n",
        "print(unique_series_descriptions)\n"
      ],
      "metadata": {
        "id": "HFOKbpb_3wV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_image_df = dicom_data[dicom_data['SeriesDescription'] == 'full mammogram images']\n",
        "full_image_df['image_path'] = full_image_df['image_path'].apply(lambda x: x.replace('CBIS-DDSM/jpeg', image_dir))"
      ],
      "metadata": {
        "id": "qmfT9YRd-wVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mass_case_df['SeriesInstanceUID'] = mass_case_df['image file path'].apply(lambda path: path.split('/')[2])"
      ],
      "metadata": {
        "id": "34_XbTn--zW6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_image_path_series_id = dict(zip(full_image_df['SeriesInstanceUID'].values,full_image_df['image_path'].values))"
      ],
      "metadata": {
        "id": "IVpi34hi1kpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mass_case_df['image_path'] = mass_case_df['SeriesInstanceUID'].apply(lambda seri: map_image_path_series_id[seri])\n",
        "mass_case_df.head(1)"
      ],
      "metadata": {
        "id": "qRRadRAlB3-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mass_case_df['pathology'].unique()\n"
      ],
      "metadata": {
        "id": "yZQq-NpsD7uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mass_case_df['pathology'].value_counts()"
      ],
      "metadata": {
        "id": "agMrhMbPQajD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6GfEtHgswzbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import albumentations as A\n",
        "from tqdm import tqdm\n",
        "\n",
        "ALLOWED_EXTENSIONS = {'jpg', 'jpeg', 'png', 'bmp', 'tiff'}\n",
        "\n",
        "mammography_augmentations = {\n",
        "\n",
        "\n",
        "    \"GaussNoise\": A.GaussNoise(var_limit=(5.0, 15.0), p=1.0),\n",
        "    \"RandomBrightnessContrast\": A.RandomBrightnessContrast(brightness_limit=0.05, contrast_limit=0.05, p=1.0),\n",
        "    \"RandomGamma\": A.RandomGamma(gamma_limit=(98, 102), p=1.0),\n",
        "    \"Equalize\": A.Equalize(p=1.0),\n",
        "    \"GaussianBlur\": A.GaussianBlur(blur_limit=1, p=1.0),\n",
        "\n",
        "}\n",
        "\n",
        "def apply_augmentations(image, augmentations):\n",
        "    augmented_images = {}\n",
        "    for aug_name, aug in augmentations.items():\n",
        "        augmented = aug(image=image)\n",
        "        augmented_images[aug_name] = augmented['image']\n",
        "    return augmented_images\n",
        "\n",
        "def balance_classes_mass(dataset_folder, images_folder, output_folder, dataframe):\n",
        "    class_counts = dataframe[\"pathology\"].value_counts()\n",
        "    min_class_count = class_counts.min()\n",
        "    max_class_count = class_counts.max()\n",
        "\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    final_data = []\n",
        "\n",
        "    for pathology in dataframe[\"pathology\"].unique():\n",
        "        df_class = dataframe[dataframe[\"pathology\"] == pathology]\n",
        "        real_images = df_class.sample(n=min_class_count, replace=False).reset_index(drop=True)\n",
        "        real_images_copy = real_images.copy()\n",
        "\n",
        "        num_augmented_needed = max_class_count - min_class_count\n",
        "        augmented_data = []\n",
        "        aug_index = 0\n",
        "\n",
        "        print(f\"{pathology}: Keeping {min_class_count} real images, generating {num_augmented_needed} augmented.\")\n",
        "\n",
        "        while len(augmented_data) < num_augmented_needed:\n",
        "            row = real_images.iloc[aug_index % len(real_images)]\n",
        "            image_path = row['image_path']\n",
        "\n",
        "            if not os.path.exists(image_path):\n",
        "                print(f\"Image not found: {image_path}\")\n",
        "                aug_index += 1\n",
        "                continue\n",
        "\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "            if image is None:\n",
        "                print(f\"Failed to load image: {image_path}\")\n",
        "                aug_index += 1\n",
        "                continue\n",
        "\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
        "\n",
        "            for aug_name, aug in mammography_augmentations.items():\n",
        "                if len(augmented_data) >= num_augmented_needed:\n",
        "                    break\n",
        "\n",
        "                augmented = aug(image=image)['image']\n",
        "                new_image_name = f\"aug_{aug_name}_{aug_index}_{os.path.basename(image_path)}\"\n",
        "                new_image_path = os.path.join(output_folder, new_image_name)\n",
        "                cv2.imwrite(new_image_path, augmented)\n",
        "\n",
        "                new_row = row.copy()\n",
        "                new_row['image_path'] = new_image_path\n",
        "                augmented_data.append(new_row)\n",
        "\n",
        "            aug_index += 1\n",
        "\n",
        "        final_data.extend(real_images_copy.to_dict('records'))\n",
        "        final_data.extend(augmented_data)\n",
        "\n",
        "    final_df = pd.DataFrame(final_data)\n",
        "    final_df.to_csv(os.path.join(dataset_folder, \"augmented_balanced_mass_dataset.csv\"), index=False)\n",
        "    print(\"Balanced dataset saved with real = min count and total = max count per class.\")"
      ],
      "metadata": {
        "id": "7c6wFQQzIivq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_classes_mass(dataset_folder='/content/dataset_folder',\n",
        "                images_folder=\"os.path.join(dataset_folder, 'jpeg')\",\n",
        "                output_folder=\"augmented_masss_images\",\n",
        "                dataframe=mass_case_df)\n"
      ],
      "metadata": {
        "id": "Pw-cC95YIkF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df = pd.read_csv(\"/content/dataset_folder/augmented_balanced_mass_dataset.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zzAmn3kGSZdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_df['pathology'].value_counts()"
      ],
      "metadata": {
        "id": "QzwKgysQZnpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "aug_df = pd.read_csv(\"/content/dataset_folder/augmented_balanced_mass_dataset.csv\")\n",
        "train_df, test_df = train_test_split(aug_df, test_size=0.2, shuffle=True, random_state=42)\n"
      ],
      "metadata": {
        "id": "dQgxzLtHTQaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "vLfkbaH5ZAPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Recreate and fit the encoders\n",
        "label_encoder_abnormality = LabelEncoder()\n",
        "label_encoder_pathology = LabelEncoder()\n",
        "\n",
        "label_encoder_abnormality.fit(train_df[\"abnormality type\"])\n",
        "label_encoder_pathology.fit(train_df[\"pathology\"])\n",
        "\n",
        "# Save the encoders to disk\n",
        "with open(\"label_encoder_abnormality.pkl\", \"wb\") as f:\n",
        "    pickle.dump(label_encoder_abnormality, f)\n",
        "with open(\"label_encoder_pathology.pkl\", \"wb\") as f:\n",
        "    pickle.dump(label_encoder_pathology, f)\n",
        "\n",
        "print(\"Encoders saved successfully as 'label_encoder_abnormality.pkl' and 'label_encoder_pathology.pkl'\")"
      ],
      "metadata": {
        "id": "qx_PSenwzuVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "\n",
        "df = train_df\n",
        "df = df[df[\"abnormality type\"] == \"mass\"]\n",
        "\n",
        "label_encoder_pathology = LabelEncoder()\n",
        "df[\"pathology_encoded\"] = label_encoder_pathology.fit_transform(df[\"pathology\"])\n",
        "num_classes_pathology = len(label_encoder_pathology.classes_)\n",
        "df[\"pathology_encoded\"] = df[\"pathology_encoded\"].apply(lambda x: tf.keras.utils.to_categorical(x, num_classes=num_classes_pathology))\n",
        "\n",
        "class SingleOutputDataGenerator(tf.keras.utils.Sequence):\n",
        "    def __init__(self, df, batch_size, img_size=(256, 256), shuffle=True):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.batch_size = batch_size\n",
        "        self.img_size = img_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.df))\n",
        "        self.on_epoch_end()\n",
        "    def __len__(self):\n",
        "        return len(self.df) // self.batch_size\n",
        "    def __getitem__(self, index):\n",
        "        idx = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        batch = self.df.iloc[idx]\n",
        "        X = np.array([img_to_array(load_img(p, target_size=self.img_size)) for p in batch[\"image_path\"]]) / 255.0\n",
        "        y = np.stack(batch[\"pathology_encoded\"].values)\n",
        "        return X, y\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "base = DenseNet121(input_shape=(256, 256, 3), include_top=False, weights=\"imagenet\")\n",
        "base.trainable = False\n",
        "\n",
        "x = base.output\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(num_classes_pathology, activation='softmax', name='pathology')(x)\n",
        "\n",
        "model = Model(inputs=base.input, outputs=output)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "train_gen = SingleOutputDataGenerator(df, batch_size=32)\n",
        "\n",
        "model.fit(train_gen, epochs=10)\n",
        "model.save(\"densenet121.h5\")\n"
      ],
      "metadata": {
        "id": "WM35rX9aPwMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume test_df is defined and contains columns: 'image_path', 'abnormality type', 'pathology'\n",
        "test_df = test_df[test_df[\"abnormality type\"] == \"mass\"]\n",
        "\n",
        "# Use the same label encoder as training\n",
        "test_df[\"pathology_encoded\"] = label_encoder_pathology.transform(test_df[\"pathology\"])\n",
        "test_df[\"pathology_encoded\"] = test_df[\"pathology_encoded\"].apply(\n",
        "    lambda x: tf.keras.utils.to_categorical(x, num_classes=num_classes_pathology)\n",
        ")\n",
        "\n",
        "# Create test data generator\n",
        "test_gen = SingleOutputDataGenerator(test_df, batch_size=32, shuffle=False)\n",
        "\n",
        "# Evaluate model\n",
        "loss, accuracy = model.evaluate(test_gen)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "xzdswQqRnncw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"densenet121.h5\")\n"
      ],
      "metadata": {
        "id": "9f1JSza8fqxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/label_encoder_pathology.pkl\")"
      ],
      "metadata": {
        "id": "S9-N7yZSRiT6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}